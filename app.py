import streamlit as st
import google.generativeai as genai
import json
import re
import random

# --- 1. ×”×’×“×¨×•×ª API ××™×•×¦×‘×•×ª ---
def setup_model():
    if "GEMINI_KEY" not in st.secrets:
        st.error("Missing GEMINI_KEY in secrets")
        return None
    genai.configure(api_key=st.secrets["GEMINI_KEY"])
    
    # × ×™×¡×™×•×Ÿ ×œ×”×©×ª××© ×‘×’×¨×¡×” ×”×™×¦×™×‘×” ×‘×™×•×ª×¨
    # ×× gemini-1.5-flash ×œ× × ××¦×, ×”××¢×¨×›×ª ×ª× ×¡×” ×œ×¢×‘×•×¨ ×œ-gemini-pro
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        # ×‘×“×™×§×” ×§×¦×¨×” ×× ×”××•×“×œ ××’×™×‘ (××•×¤×¦×™×•× ×œ×™, ×›××Ÿ × ×’×“×™×¨ ×¨×§ ××ª ×”×©×)
        return model
    except:
        try:
            return genai.GenerativeModel('gemini-pro')
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ××¦×•× ××•×“×œ × ×ª××š: {e}")
            return None

# --- 2. ×¢×™×¦×•×‘ ×××©×§ ---
st.set_page_config(page_title="×§×‘×™× ×˜ ×”××•×—×•×ª", layout="wide")
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Assistant:wght@400;700&display=swap');
    html, body, [class*="st-"] { font-family: 'Assistant', sans-serif; direction: rtl; text-align: right; background-color: #0f172a; }
    .stTextArea textarea { color: #000000 !important; background-color: #ffffff !important; border: 2px solid #3b82f6 !important; }
    label, p, h1, h2 { color: #f8fafc !important; }
    </style>
""", unsafe_allow_html=True)

# --- 3. ×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×œ×—×™×œ×•×¥ JSON ---
def extract_json(text):
    try:
        # ××—×¤×© ××ª ×”××¢×¨×š ×‘×ª×•×š ×”×˜×§×¡×˜
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            return json.loads(match.group())
    except:
        pass
    return None

# --- 4. × ×™×”×•×œ ×”××¦×‘ ---
if 'step' not in st.session_state: st.session_state.step = 'setup'
if 'history' not in st.session_state: st.session_state.history = []

# --- ×©×œ×‘ 0: ××¡×š ×¤×ª×™×—×” ---
if st.session_state.step == 'setup':
    st.title("ğŸ›ï¸ ×§×‘×™× ×˜ ×”××•×—×•×ª")
    idea = st.text_area("ğŸ–‹ï¸ ×ª××¨ ××ª ×”×“×™×œ××” ×©×œ×š:", height=150)
    
    if st.button("ğŸ” ×”×ª×—×œ ××‘×—×•×Ÿ"):
        model = setup_model()
        if model and idea:
            st.session_state.user_idea = idea
            with st.spinner("×”×§×‘×™× ×˜ ××’×‘×© ×©××œ×•×ª..."):
                prompt = (
                    f"Topic: {idea}. Task: 3 diagnostic questions in Hebrew. "
                    "Return ONLY a plain JSON array: [{'q':'question', 'options':['a','b','c']}]"
                )
                try:
                    response = model.generate_content(prompt)
                    questions = extract_json(response.text)
                    if questions:
                        st.session_state.questions = questions
                        st.session_state.step = 'diagnostic'
                        st.rerun()
                    else:
                        st.warning("×”×§×‘×™× ×˜ ×œ× ×”×¦×œ×™×— ×œ×™×™×¦×¨ ×©××œ×•×ª ×‘×¤×•×¨××˜ ×”× ×›×•×Ÿ. × ×¡×” ×©×•×‘.")
                except Exception as e:
                    st.error(f"×©×’×™××ª ×ª×§×©×•×¨×ª ×¢× ×”××•×“×œ: {e}")

# --- ×©×œ×‘ 1: ××‘×—×•×Ÿ ---
elif st.session_state.step == 'diagnostic':
    st.title("ğŸ“ ××‘×—×•×Ÿ")
    ans_list = []
    for i, item in enumerate(st.session_state.questions):
        ans = st.radio(f"**{item['q']}**", item['options'], key=f"q_{i}")
        ans_list.append(f"Q: {item['q']} | A: {ans}")
    
    if st.button("ğŸš€ ×”××©×š ×œ×“×™×•×Ÿ"):
        st.session_state.history.append({"role": "user", "content": f"××§×¨×”: {st.session_state.user_idea}. ××‘×—×•×Ÿ: {ans_list}"})
        st.session_state.step = 'dialogue'
        st.rerun()

# --- ×©×œ×‘ 2: ×“×™××œ×•×’ ---
elif st.session_state.step == 'dialogue':
    st.title("ğŸ’¬ ×“×™×•×Ÿ ×‘×§×‘×™× ×˜")
    
    for msg in st.session_state.history:
        if "××§×¨×”:" in msg['content'] and len(st.session_state.history) > 1: continue
        with st.chat_message("assistant" if msg['role'] == "model" else "user"):
            st.write(msg['content'])

    if not st.session_state.history or st.session_state.history[-1]['role'] == 'user':
        with st.chat_message("assistant"):
            with st.spinner("×—×‘×¨ ×§×‘×™× ×˜ ××©×™×‘..."):
                model = setup_model()
                expert = random.choice(["×¡×•×§×¨×˜×¡", "××¨×§×•×¡ ××•×¨×œ×™×•×¡", "×•×™×§×˜×•×¨ ×¤×¨×× ×§×œ", "×™×•× ×’"])
                instr = f"You are {expert}. Respond in Hebrew. Open with: '{expert} ×”×™×” × ×•×”×’ ×œ×•××¨...'. Be deep and brief."
                
                # ×‘× ×™×™×ª ×”×™×¡×˜×•×¨×™×” ×ª×§×™× ×”
                gemini_hist = [{"role": m['role'], "parts": [m['content']]} for m in st.session_state.history]
                try:
                    res = model.generate_content([{"role": "user", "parts": [instr]}] + gemini_hist)
                    st.write(res.text)
                    st.session_state.history.append({"role": "model", "content": res.text})
                except Exception as e:
                    st.error(f"×©×’×™××” ×‘×§×‘×œ×ª ×ª×’×•×‘×”: {e}")

    if reply := st.chat_input("×”×©×‘..."):
        st.session_state.history.append({"role": "user", "content": reply})
        st.rerun()